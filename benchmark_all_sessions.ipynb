{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48733df3-64a9-4021-a6ad-bcfaa1204838",
   "metadata": {},
   "source": [
    "### Show how accuracy varies across mice by running LSTM on all sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d68df0-0e46-4e07-9c42-799fb01d612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv('output/session_details.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a346e41d-6266-4bfc-9c24-6bc98380a4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 20.0, Train Acc: 0.97%, Test Acc: 0.42%\n",
      "Epoch 2, Loss: 19.91, Train Acc: 0.97%, Test Acc: 0.59%\n",
      "Epoch 3, Loss: 19.86, Train Acc: 1.03%, Test Acc: 0.42%\n",
      "Epoch 4, Loss: 19.8, Train Acc: 1.12%, Test Acc: 0.42%\n",
      "Epoch 5, Loss: 19.75, Train Acc: 1.12%, Test Acc: 0.42%\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def run_lstm_model(hidden_dim, layer_dim, learning_rate, num_epochs, batch_size, seq_len, session_details_file_path, spike_trains_file_path):\n",
    "    # Function to save session details to a CSV file\n",
    "    def save_session_details(session_details):\n",
    "        fieldnames = [\n",
    "            'session_number', 'bins', 'model_name', 'test_acc', \n",
    "            'train_acc', 'num_epochs', 'hidden_dim', 'layer_dim', \n",
    "            'learning_rate', 'batch_size'\n",
    "        ]\n",
    "        \n",
    "        # Check if the file exists\n",
    "        file_exists = os.path.isfile(session_details_file_path)\n",
    "        \n",
    "        # Open the file in append mode\n",
    "        with open(session_details_file_path, 'a', newline='') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            \n",
    "            # Write the header if the file does not exist\n",
    "            if not file_exists:\n",
    "                writer.writeheader()\n",
    "            \n",
    "            # Write the session details\n",
    "            writer.writerow(session_details)\n",
    "\n",
    "    with open(spike_trains_file_path, 'rb') as f:\n",
    "        spike_df = pickle.load(f)\n",
    "\n",
    "    # Create X and y\n",
    "    X = spike_df.drop(columns=['frame']).values\n",
    "    y = spike_df['frame'].values\n",
    "\n",
    "    # Encode categorical target values\n",
    "    encoder = LabelEncoder()\n",
    "    y_encoded = encoder.fit_transform(y)\n",
    "    output_dim = len(np.unique(y_encoded))\n",
    "\n",
    "    # Create train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "    num_samples_train = X_train.shape[0] // seq_len\n",
    "    num_features = X_train.shape[1]\n",
    "    num_samples_test = X_test.shape[0] // seq_len\n",
    "\n",
    "    # Reshape input and output to have 3 dimensions\n",
    "    X_train = X_train[:num_samples_train*seq_len].reshape(num_samples_train, seq_len, num_features)\n",
    "    y_train = y_train[:num_samples_train*seq_len].reshape(num_samples_train, seq_len, 1)[:, -1]\n",
    "    X_test = X_test[:num_samples_test*seq_len].reshape(num_samples_test, seq_len, num_features)\n",
    "    y_test = y_test[:num_samples_test*seq_len].reshape(num_samples_test, seq_len, 1)[:, -1]\n",
    "\n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    # Define LSTM model\n",
    "    class LSTMModel(nn.Module):\n",
    "        def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "            super(LSTMModel, self).__init__()\n",
    "            self.hidden_dim = hidden_dim\n",
    "            self.layer_dim = layer_dim\n",
    "            self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "            self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        def forward(self, x):\n",
    "            h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
    "            c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
    "            out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "            out = self.fc(out[:, -1, :])\n",
    "            return out\n",
    "\n",
    "    # Check if GPU is available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Set model parameters\n",
    "    input_dim = X_train.shape[-1]\n",
    "\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Create DataLoaders for training and testing data\n",
    "    train_loader = DataLoader(list(zip(X_train, y_train)), batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(list(zip(X_test, y_test)), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_running_loss = 0.0\n",
    "        correct_train_preds = 0.0\n",
    "        total_train_samples = 0.0\n",
    "        for i, (features, labels) in enumerate(train_loader):\n",
    "            features = features.view(-1, seq_len, input_dim).to(device)\n",
    "            labels = labels.to(device)\n",
    "            out = model(features)\n",
    "            labels = labels.view(-1)\n",
    "            if labels.dim() > 1:\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            labels = labels.long()\n",
    "            loss = criterion(out, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_running_loss += loss.detach().item()\n",
    "            _, preds = torch.max(out, dim=1)\n",
    "            correct_train_preds += (preds == labels).sum().item()\n",
    "            total_train_samples += labels.shape[0]\n",
    "\n",
    "        model.eval()\n",
    "        correct_test_preds = 0.0\n",
    "        total_test_samples = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, (features, labels) in enumerate(test_loader):\n",
    "                features = features.view(-1, seq_len, input_dim).to(device)\n",
    "                labels = labels.to(device).squeeze()\n",
    "                out = model(features)\n",
    "                _, preds = torch.max(out, dim=1)\n",
    "                correct_test_preds += (preds == labels).sum().item()\n",
    "                total_test_samples += labels.shape[0]\n",
    "\n",
    "        train_acc = correct_train_preds / total_train_samples * 100\n",
    "        test_acc = correct_test_preds / total_test_samples * 100\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Loss: {np.round(train_running_loss/i,2)}, Train Acc: {np.round(train_acc,2)}%, Test Acc: {np.round(test_acc,2)}%')\n",
    "\n",
    "    # Save session details after the final epoch\n",
    "    session_details = {\n",
    "        'session_number': spike_trains_file_path.split('_')[-2].split('_')[0],\n",
    "        'bins': seq_len,\n",
    "        'model_name': 'LSTM',\n",
    "        'test_acc': np.round(test_acc, 2),\n",
    "        'train_acc': np.round(train_acc, 2),\n",
    "        'num_epochs': num_epochs,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'layer_dim': layer_dim,\n",
    "        'learning_rate': learning_rate,\n",
    "        'batch_size': batch_size\n",
    "    }\n",
    "    save_session_details(session_details)\n",
    "\n",
    "# Example call to the function\n",
    "run_lstm_model(\n",
    "    hidden_dim=2,\n",
    "    layer_dim=1,\n",
    "    learning_rate=0.001,\n",
    "    num_epochs=5,\n",
    "    batch_size=64,\n",
    "    seq_len=5,\n",
    "    session_details_file_path='output/session_details.csv',\n",
    "    spike_trains_file_path='output/spike_trains_with_stimulus_session_715093703_5.pkl'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7af767a4-82d4-4e2c-8c39-0757fb759dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_keys =[715093703, 719161530, 721123822, 732592105, 737581020, 739448407, 742951821, 743475441, 744228101, 746083955, 750332458, 750749662, 751348571, 754312389, 754829445, 755434585, 756029989, 757216464, 757970808, 758798717, 759883607, 760345702, 760693773, 761418226, 762120172, 762602078, 763673393, 766640955, 767871931, 768515987, 771160300, 771990200, 773418906, 774875821, 778240327, 778998620, 779839471, 781842082, 786091066, 787025148, 789848216, 791319847, 793224716, 794812542, 797828357, 798911424, 799864342, 816200189, 819186360, 819701982, 821695405, 829720705, 831882777, 835479236, 839068429, 839557629, 840012044, 847657808]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea4635c1-189c-4ee1-adb0-ecdfa871d2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_keys =[ 755434585, 756029989]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e20f24-a004-457b-ae6f-473e5ef77232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 18.72, Train Acc: 7.77%, Test Acc: 21.76%\n",
      "Epoch 2, Loss: 10.69, Train Acc: 55.24%, Test Acc: 78.57%\n",
      "Epoch 3, Loss: 3.31, Train Acc: 90.67%, Test Acc: 89.24%\n"
     ]
    }
   ],
   "source": [
    "for i in session_keys:\n",
    "    # Example call to the function\n",
    "    run_lstm_model(\n",
    "        hidden_dim = 500,\n",
    "        layer_dim = 1,\n",
    "        learning_rate = 0.001,\n",
    "        num_epochs = 10,\n",
    "        batch_size = 64,\n",
    "        seq_len = 5,\n",
    "        session_details_file_path='output/session_details.csv',\n",
    "        spike_trains_file_path= f'spike_trains_with_stimulus_session_{i}_5.pkl'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0f90f1-03a3-4554-b510-4b14f36bacb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
