{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18288bfb-04bd-494d-a97f-846ad35276ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA GPU is available.\n",
      "Current GPU device: NVIDIA A100-PCIE-40GB\n",
      "Total RAM: 1006.92 GB\n",
      "Available RAM: 862.29 GB\n",
      "Using existing manifest.json file.\n",
      "Session keys:\n",
      "[715093703, 719161530, 721123822, 732592105, 737581020, 739448407, 742951821, 743475441, 744228101, 746083955, 750332458, 750749662, 751348571, 754312389, 754829445, 755434585, 756029989, 757216464, 757970808, 758798717, 759883607, 760345702, 760693773, 761418226, 762120172, 762602078, 763673393, 766640955, 767871931, 768515987, 771160300, 771990200, 773418906, 774875821, 778240327, 778998620, 779839471, 781842082, 786091066, 787025148, 789848216, 791319847, 793224716, 794812542, 797828357, 798911424, 799864342, 816200189, 819186360, 819701982, 821695405, 829720705, 831882777, 835479236, 839068429, 839557629, 840012044, 847657808]\n"
     ]
    }
   ],
   "source": [
    "# Setup Environment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import psutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv, GATv2Conv\n",
    "from torch.nn import Linear\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA GPU is available.\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"CUDA GPU is not available. Using CPU instead.\")\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(f\"Current GPU device: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "print(f\"Total RAM: {(psutil.virtual_memory().total / (1024**3)):.2f} GB\")\n",
    "print(f\"Available RAM: {(psutil.virtual_memory().available / (1024**3)):.2f} GB\")\n",
    "\n",
    "from allensdk.core.brain_observatory_cache import BrainObservatoryCache\n",
    "from allensdk.brain_observatory.ecephys.ecephys_project_cache import EcephysProjectCache \n",
    "\n",
    "# Set output directory to a new folder called 'output' in the current working directory\n",
    "output_dir = os.path.join(os.getcwd(), 'output')\n",
    "\n",
    "# Check if the output directory exists, and create it if it doesn't\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Set DOWNLOAD_COMPLETE_DATASET to True\n",
    "DOWNLOAD_COMPLETE_DATASET = True\n",
    "\n",
    "# Create a file path to the manifest.json file within the output directory\n",
    "manifest_path = os.path.join(output_dir, \"manifest.json\")\n",
    "\n",
    "# Check if the manifest.json file exists\n",
    "if os.path.exists(manifest_path):\n",
    "    print(\"Using existing manifest.json file.\")\n",
    "else:\n",
    "    print(\"Creating a new manifest.json file.\")\n",
    "\n",
    "# Create an instance of the EcephysProjectCache class with the manifest file path as argument\n",
    "cache = EcephysProjectCache(manifest=manifest_path)\n",
    "# Get session table\n",
    "session_table = cache.get_session_table()\n",
    "\n",
    "# Display session keys\n",
    "session_keys = []\n",
    "print(\"Session keys:\")\n",
    "for session_key in session_table.index:\n",
    "    session_keys.append(session_key)\n",
    "print(session_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "018f4a85-fc07-462a-99f3-16807388de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = [ 750332458, 750749662, 751348571, 754312389, 754829445, 755434585, 756029989, 757216464, 757970808, 758798717, 759883607, 760345702, 760693773, 761418226, 762120172, 762602078, 763673393, 766640955, 767871931, 768515987, 771160300, 771990200, 773418906, 774875821, 778240327, 778998620, 779839471, 781842082, 786091066, 787025148, 789848216, 791319847, 793224716, 794812542, 797828357, 798911424, 799864342, 816200189, 819186360, 819701982, 821695405, 829720705, 831882777, 835479236, 839068429, 839557629, 840012044, 847657808]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22d4599-ba35-4eb1-b68e-1a432ba3eed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/longleaf/home/rayrayc/.local/lib/python3.10/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.1.3 because version 1.8.0 is already loaded.\n",
      "  return func(args[0], **pargs)\n",
      "/nas/longleaf/home/rayrayc/.local/lib/python3.10/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'core' version 2.2.2 because version 2.7.0 is already loaded.\n",
      "  return func(args[0], **pargs)\n",
      "/nas/longleaf/home/rayrayc/.local/lib/python3.10/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.1.3 because version 1.8.0 is already loaded.\n",
      "  return func(args[0], **pargs)\n",
      "/nas/longleaf/home/rayrayc/.local/lib/python3.10/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'core' version 2.2.2 because version 2.7.0 is already loaded.\n",
      "  return func(args[0], **pargs)\n",
      "/nas/longleaf/home/rayrayc/.local/lib/python3.10/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.1.3 because version 1.8.0 is already loaded.\n",
      "  return func(args[0], **pargs)\n",
      "/nas/longleaf/home/rayrayc/.local/lib/python3.10/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'core' version 2.2.2 because version 2.7.0 is already loaded.\n",
      "  return func(args[0], **pargs)\n",
      "/nas/longleaf/home/rayrayc/.local/lib/python3.10/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.1.3 because version 1.8.0 is already loaded.\n",
      "  return func(args[0], **pargs)\n",
      "/nas/longleaf/home/rayrayc/.local/lib/python3.10/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'core' version 2.2.2 because version 2.7.0 is already loaded.\n",
      "  return func(args[0], **pargs)\n",
      "/nas/longleaf/home/rayrayc/.local/lib/python3.10/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.1.3 because version 1.8.0 is already loaded.\n",
      "  return func(args[0], **pargs)\n",
      "/nas/longleaf/home/rayrayc/.local/lib/python3.10/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'core' version 2.2.2 because version 2.7.0 is already loaded.\n",
      "  return func(args[0], **pargs)\n",
      "/nas/longleaf/home/rayrayc/.local/lib/python3.10/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.1.3 because version 1.8.0 is already loaded.\n",
      "  return func(args[0], **pargs)\n",
      "/nas/longleaf/home/rayrayc/.local/lib/python3.10/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'core' version 2.2.2 because version 2.7.0 is already loaded.\n",
      "  return func(args[0], **pargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session objects\n",
      "['DETAILED_STIMULUS_PARAMETERS', 'LazyProperty', 'age_in_days', 'api', 'channel_structure_intervals', 'channels', 'conditionwise_spike_statistics', 'ecephys_session_id', 'from_nwb_path', 'full_genotype', 'get_current_source_density', 'get_inter_presentation_intervals_for_stimulus', 'get_invalid_times', 'get_lfp', 'get_parameter_values_for_stimulus', 'get_pupil_data', 'get_screen_gaze_data', 'get_stimulus_epochs', 'get_stimulus_parameter_values', 'get_stimulus_table', 'inter_presentation_intervals', 'invalid_times', 'mean_waveforms', 'metadata', 'num_channels', 'num_probes', 'num_stimulus_presentations', 'num_units', 'optogenetic_stimulation_epochs', 'presentationwise_spike_counts', 'presentationwise_spike_times', 'probes', 'rig_equipment_name', 'rig_geometry_data', 'running_speed', 'session_start_time', 'session_type', 'sex', 'specimen_name', 'spike_amplitudes', 'spike_times', 'stimulus_conditions', 'stimulus_names', 'stimulus_presentations', 'structure_acronyms', 'structurewise_unit_counts', 'units']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering valid spike times: 100%|██████████| 2118/2118 [00:00<00:00, 5558.15it/s]\n",
      "Processing neurons: 100%|██████████| 2118/2118 [02:03<00:00, 17.15it/s]\n",
      "WARNING:root:downloading a 2687.881MiB file from http://api.brain-map.org//api/v2/well_known_file_download/1026124242\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5350e9c2b52b4d3ab50c7cdbe297279c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.82G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session objects\n",
      "['DETAILED_STIMULUS_PARAMETERS', 'LazyProperty', 'age_in_days', 'api', 'channel_structure_intervals', 'channels', 'conditionwise_spike_statistics', 'ecephys_session_id', 'from_nwb_path', 'full_genotype', 'get_current_source_density', 'get_inter_presentation_intervals_for_stimulus', 'get_invalid_times', 'get_lfp', 'get_parameter_values_for_stimulus', 'get_pupil_data', 'get_screen_gaze_data', 'get_stimulus_epochs', 'get_stimulus_parameter_values', 'get_stimulus_table', 'inter_presentation_intervals', 'invalid_times', 'mean_waveforms', 'metadata', 'num_channels', 'num_probes', 'num_stimulus_presentations', 'num_units', 'optogenetic_stimulation_epochs', 'presentationwise_spike_counts', 'presentationwise_spike_times', 'probes', 'rig_equipment_name', 'rig_geometry_data', 'running_speed', 'session_start_time', 'session_type', 'sex', 'specimen_name', 'spike_amplitudes', 'spike_times', 'stimulus_conditions', 'stimulus_names', 'stimulus_presentations', 'structure_acronyms', 'structurewise_unit_counts', 'units']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering valid spike times: 100%|██████████| 1887/1887 [00:00<00:00, 4232.31it/s]\n",
      "Processing neurons: 100%|██████████| 1887/1887 [01:54<00:00, 16.49it/s]\n",
      "WARNING:root:downloading a 2930.954MiB file from http://api.brain-map.org//api/v2/well_known_file_download/1026124863\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de568912cea34db2a199b030b0521009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.07G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session objects\n",
      "['DETAILED_STIMULUS_PARAMETERS', 'LazyProperty', 'age_in_days', 'api', 'channel_structure_intervals', 'channels', 'conditionwise_spike_statistics', 'ecephys_session_id', 'from_nwb_path', 'full_genotype', 'get_current_source_density', 'get_inter_presentation_intervals_for_stimulus', 'get_invalid_times', 'get_lfp', 'get_parameter_values_for_stimulus', 'get_pupil_data', 'get_screen_gaze_data', 'get_stimulus_epochs', 'get_stimulus_parameter_values', 'get_stimulus_table', 'inter_presentation_intervals', 'invalid_times', 'mean_waveforms', 'metadata', 'num_channels', 'num_probes', 'num_stimulus_presentations', 'num_units', 'optogenetic_stimulation_epochs', 'presentationwise_spike_counts', 'presentationwise_spike_times', 'probes', 'rig_equipment_name', 'rig_geometry_data', 'running_speed', 'session_start_time', 'session_type', 'sex', 'specimen_name', 'spike_amplitudes', 'spike_times', 'stimulus_conditions', 'stimulus_names', 'stimulus_presentations', 'structure_acronyms', 'structurewise_unit_counts', 'units']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering valid spike times: 100%|██████████| 1985/1985 [00:00<00:00, 3722.97it/s]\n",
      "Processing neurons: 100%|██████████| 1985/1985 [02:05<00:00, 15.81it/s]\n",
      "WARNING:root:downloading a 1773.400MiB file from http://api.brain-map.org//api/v2/well_known_file_download/1026123537\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cffcc2a36aa4150ba0d07e940c4dab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session objects\n",
      "['DETAILED_STIMULUS_PARAMETERS', 'LazyProperty', 'age_in_days', 'api', 'channel_structure_intervals', 'channels', 'conditionwise_spike_statistics', 'ecephys_session_id', 'from_nwb_path', 'full_genotype', 'get_current_source_density', 'get_inter_presentation_intervals_for_stimulus', 'get_invalid_times', 'get_lfp', 'get_parameter_values_for_stimulus', 'get_pupil_data', 'get_screen_gaze_data', 'get_stimulus_epochs', 'get_stimulus_parameter_values', 'get_stimulus_table', 'inter_presentation_intervals', 'invalid_times', 'mean_waveforms', 'metadata', 'num_channels', 'num_probes', 'num_stimulus_presentations', 'num_units', 'optogenetic_stimulation_epochs', 'presentationwise_spike_counts', 'presentationwise_spike_times', 'probes', 'rig_equipment_name', 'rig_geometry_data', 'running_speed', 'session_start_time', 'session_type', 'sex', 'specimen_name', 'spike_amplitudes', 'spike_times', 'stimulus_conditions', 'stimulus_names', 'stimulus_presentations', 'structure_acronyms', 'structurewise_unit_counts', 'units']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering valid spike times: 100%|██████████| 1192/1192 [00:00<00:00, 2522.55it/s]\n",
      "Processing neurons: 100%|██████████| 1192/1192 [01:14<00:00, 16.04it/s]\n",
      "WARNING:root:downloading a 2571.776MiB file from http://api.brain-map.org//api/v2/well_known_file_download/1026124326\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23757f6e77646f79a45ba37d2898cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.70G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session objects\n",
      "['DETAILED_STIMULUS_PARAMETERS', 'LazyProperty', 'age_in_days', 'api', 'channel_structure_intervals', 'channels', 'conditionwise_spike_statistics', 'ecephys_session_id', 'from_nwb_path', 'full_genotype', 'get_current_source_density', 'get_inter_presentation_intervals_for_stimulus', 'get_invalid_times', 'get_lfp', 'get_parameter_values_for_stimulus', 'get_pupil_data', 'get_screen_gaze_data', 'get_stimulus_epochs', 'get_stimulus_parameter_values', 'get_stimulus_table', 'inter_presentation_intervals', 'invalid_times', 'mean_waveforms', 'metadata', 'num_channels', 'num_probes', 'num_stimulus_presentations', 'num_units', 'optogenetic_stimulation_epochs', 'presentationwise_spike_counts', 'presentationwise_spike_times', 'probes', 'rig_equipment_name', 'rig_geometry_data', 'running_speed', 'session_start_time', 'session_type', 'sex', 'specimen_name', 'spike_amplitudes', 'spike_times', 'stimulus_conditions', 'stimulus_names', 'stimulus_presentations', 'structure_acronyms', 'structurewise_unit_counts', 'units']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering valid spike times: 100%|██████████| 1791/1791 [00:00<00:00, 4537.98it/s]\n",
      "Processing neurons: 100%|██████████| 1791/1791 [01:56<00:00, 15.39it/s]\n",
      "WARNING:root:downloading a 2132.111MiB file from http://api.brain-map.org//api/v2/well_known_file_download/1026124684\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf85e217c0143508288e050b3854c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session objects\n",
      "['DETAILED_STIMULUS_PARAMETERS', 'LazyProperty', 'age_in_days', 'api', 'channel_structure_intervals', 'channels', 'conditionwise_spike_statistics', 'ecephys_session_id', 'from_nwb_path', 'full_genotype', 'get_current_source_density', 'get_inter_presentation_intervals_for_stimulus', 'get_invalid_times', 'get_lfp', 'get_parameter_values_for_stimulus', 'get_pupil_data', 'get_screen_gaze_data', 'get_stimulus_epochs', 'get_stimulus_parameter_values', 'get_stimulus_table', 'inter_presentation_intervals', 'invalid_times', 'mean_waveforms', 'metadata', 'num_channels', 'num_probes', 'num_stimulus_presentations', 'num_units', 'optogenetic_stimulation_epochs', 'presentationwise_spike_counts', 'presentationwise_spike_times', 'probes', 'rig_equipment_name', 'rig_geometry_data', 'running_speed', 'session_start_time', 'session_type', 'sex', 'specimen_name', 'spike_amplitudes', 'spike_times', 'stimulus_conditions', 'stimulus_names', 'stimulus_presentations', 'structure_acronyms', 'structurewise_unit_counts', 'units']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering valid spike times: 100%|██████████| 1540/1540 [00:00<00:00, 4453.49it/s]\n",
      "Processing neurons: 100%|██████████| 1540/1540 [01:32<00:00, 16.69it/s]\n",
      "WARNING:root:downloading a 2461.626MiB file from http://api.brain-map.org//api/v2/well_known_file_download/1026124216\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c75aa3781a44b4b2b65e4011119037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.58G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session objects\n",
      "['DETAILED_STIMULUS_PARAMETERS', 'LazyProperty', 'age_in_days', 'api', 'channel_structure_intervals', 'channels', 'conditionwise_spike_statistics', 'ecephys_session_id', 'from_nwb_path', 'full_genotype', 'get_current_source_density', 'get_inter_presentation_intervals_for_stimulus', 'get_invalid_times', 'get_lfp', 'get_parameter_values_for_stimulus', 'get_pupil_data', 'get_screen_gaze_data', 'get_stimulus_epochs', 'get_stimulus_parameter_values', 'get_stimulus_table', 'inter_presentation_intervals', 'invalid_times', 'mean_waveforms', 'metadata', 'num_channels', 'num_probes', 'num_stimulus_presentations', 'num_units', 'optogenetic_stimulation_epochs', 'presentationwise_spike_counts', 'presentationwise_spike_times', 'probes', 'rig_equipment_name', 'rig_geometry_data', 'running_speed', 'session_start_time', 'session_type', 'sex', 'specimen_name', 'spike_amplitudes', 'spike_times', 'stimulus_conditions', 'stimulus_names', 'stimulus_presentations', 'structure_acronyms', 'structurewise_unit_counts', 'units']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering valid spike times: 100%|██████████| 1641/1641 [00:00<00:00, 2531.04it/s]\n",
      "Processing neurons: 100%|██████████| 1641/1641 [01:53<00:00, 14.44it/s]\n",
      "WARNING:root:downloading a 2898.930MiB file from http://api.brain-map.org//api/v2/well_known_file_download/1026124603\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720da859a0d14a7197188f91f75fd6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in sessions:\n",
    "    session_number = i\n",
    "    \n",
    "    # Pull session.\n",
    "    session = cache.get_session_data(session_number,\n",
    "                                     isi_violations_maximum = np.inf,\n",
    "                                     amplitude_cutoff_maximum = np.inf,\n",
    "                                     presence_ratio_minimum = -np.inf\n",
    "                                    )\n",
    "    # Get spike times.\n",
    "    spike_times = session.spike_times\n",
    "    # Get specific stimulus table.\n",
    "    stimulus_table = session.get_stimulus_table(\"natural_scenes\")\n",
    "\n",
    "    # Display objects within session.\n",
    "    print(\"Session objects\")\n",
    "    print([attr_or_method for attr_or_method in dir(session) if attr_or_method[0] != '_'])\n",
    "    \n",
    "    # Access the invalid_times DataFrame\n",
    "    invalid_times = session.invalid_times\n",
    "\n",
    "    # Function to check if a spike time is valid\n",
    "    def is_valid_time(spike_times, invalid_intervals):\n",
    "        invalid = np.zeros_like(spike_times, dtype=bool)\n",
    "        for _, row in invalid_intervals.iterrows():\n",
    "            start, end = row['start_time'], row['stop_time']\n",
    "            invalid |= (spike_times >= start) & (spike_times <= end)\n",
    "        return ~invalid\n",
    "\n",
    "    # Filter the valid spike times\n",
    "    valid_spike_times = {}\n",
    "    with tqdm(total=len(spike_times), desc='Filtering valid spike times') as pbar:\n",
    "        for neuron, times in spike_times.items():\n",
    "            valid_mask = is_valid_time(times, session.invalid_times)\n",
    "            valid_spike_times[neuron] = times[valid_mask]\n",
    "            pbar.update(1)\n",
    "            \n",
    "    import concurrent.futures\n",
    "\n",
    "    # Parameters\n",
    "    timesteps_per_frame = 5  # Set the number of timesteps per frame\n",
    "\n",
    "    # Stimulus table.\n",
    "    stimulus_table = session.get_stimulus_table(\"natural_scenes\")\n",
    "\n",
    "    # The start times of each stimulus presentation\n",
    "    image_start_times = torch.tensor(stimulus_table.start_time.values)\n",
    "\n",
    "    # The end times of each stimulus presentation\n",
    "    image_end_times = torch.tensor(stimulus_table.stop_time.values)\n",
    "\n",
    "    # The duration of each image presentation\n",
    "    image_durations = image_end_times - image_start_times\n",
    "\n",
    "    # The bin size for each image presentation\n",
    "    bin_sizes = image_durations / timesteps_per_frame\n",
    "\n",
    "    # The number of bins per image presentation\n",
    "    bins_per_image = timesteps_per_frame\n",
    "\n",
    "    # The total number of bins\n",
    "    total_bins = bins_per_image * len(image_start_times)\n",
    "\n",
    "    # Create an empty binary spike matrix\n",
    "    num_neurons = len(spike_times.keys())\n",
    "\n",
    "    def process_neuron(times):\n",
    "        # The start bin for the next image presentation\n",
    "        start_bin = 0\n",
    "        neuron_spike_bins = torch.zeros(total_bins, dtype=torch.int32)\n",
    "        for image_idx, (start_time, end_time) in enumerate(zip(image_start_times, image_end_times)):\n",
    "            # Bin edges for this image presentation\n",
    "            bin_edges = torch.linspace(start_time, end_time, bins_per_image + 1)\n",
    "\n",
    "            # Bin the spike times for this image presentation\n",
    "            binned_spike_times = torch.histc(torch.tensor(times), bins=bin_edges.shape[0]-1, min=bin_edges.min(), max=bin_edges.max())\n",
    "\n",
    "            # Add the binned spike times to the spike matrix\n",
    "            end_bin = start_bin + bins_per_image\n",
    "            if len(binned_spike_times) == len(neuron_spike_bins[start_bin:end_bin]):\n",
    "                neuron_spike_bins[start_bin:end_bin] = binned_spike_times\n",
    "\n",
    "            # Update the start bin for the next image presentation\n",
    "            start_bin = end_bin\n",
    "        return neuron_spike_bins\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        spike_matrix = list(tqdm(executor.map(process_neuron, spike_times.values()), total=num_neurons, desc='Processing neurons'))\n",
    "\n",
    "    spike_matrix = torch.stack(spike_matrix)\n",
    "\n",
    "    # Convert the spike matrix to a pandas DataFrame and set the index to neuron IDs\n",
    "    spike_dataframe = pd.DataFrame(spike_matrix.numpy(), index=spike_times.keys())\n",
    "\n",
    "    spike_dataframe.T\n",
    "    \n",
    "    spike_df = spike_dataframe.T\n",
    "    spike_df['frame'] = 'nan'\n",
    "    spike_df['frame'] = np.repeat(np.array(stimulus_table['frame']), timesteps_per_frame)\n",
    "\n",
    "    #Save the dictionary of valid spike times to a pickle file\n",
    "    with open(f'spike_trains_with_stimulus_session_{session_number}_{timesteps_per_frame}.pkl', 'wb') as f:\n",
    "        pickle.dump(spike_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a1899f9-418a-4e0f-b950-eed10766c098",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'spike_trains_with_stimulus_session_715093703_5.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspike_trains_with_stimulus_session_715093703_5.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/pickle.py:190\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'spike_trains_with_stimulus_session_715093703_5.pkl'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_pickle('spike_trains_with_stimulus_session_715093703_5.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aad0dd-b1d7-461e-af18-44ca6e4d95f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
